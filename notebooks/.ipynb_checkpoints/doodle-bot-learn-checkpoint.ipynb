{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doodle-bot-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a code along with the talk I gave on the use of GANs to generate images.\n",
    "While I have been able to do this on a more interesting dataset, the results are more difficult to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this is drawn from the tensorflow models tutorials, which can be found [here](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SLIM = \"../models/research\"\n",
    "sys.path.append(PATH_TO_SLIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TFGAN = '../models/research/gan/'\n",
    "sys.path.append(PATH_TO_TFGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcuts for variables\n",
    "tfgan = tf.contrib.gan\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md         cgan.py           \u001b[34mmodels\u001b[m\u001b[m            visualizer.py\r\n",
      "__init__.py       cross_entropy.png \u001b[34mnotebooks\u001b[m\u001b[m         xent_score.png\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m       evaluate.py       setup.sh\r\n",
      "\u001b[34massets\u001b[m\u001b[m            \u001b[34mexample_output\u001b[m\u001b[m    tf_nets.py\r\n",
      "cgan-flowers.py   loss.png          training_loss.png\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../')  # go to main folder of the repo\n",
    "\n",
    "! ls # confirm that you're there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules created for the project\n",
    "import visualizer\n",
    "import tf_nets\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5b9d3ac30876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m  \u001b[0;31m# tf-slim data provider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/repos/models/research/gan/mnist/data_provider.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_factory\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mslim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/repos/models/research/slim/datasets/dataset_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflowers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import slim\n",
    "\n",
    "from mnist import data_provider, util  # tf-slim data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slim.datasets import download_and_convert_mnist  # slim mnist downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/tmp/mnist/\"\n",
    "LOG_DIR = \"assets/saved_models/\"\n",
    "RESULT_DIR = \"assets/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tf.gfile.Exists(DATA_DIR):  # check if data directory already exists\n",
    "    tf.gfile.MakeDirs(DATA_DIR)\n",
    "\n",
    "download_and_convert_mnist.run(DATA_DIR)  # download data if missing\n",
    "\n",
    "batch_size = 32\n",
    "with tf.device('/cpu:0'):  # pin it to the cpu and save gpu for propagation\n",
    "    images, one_hot_labels, _ = data_provider.provide_data('train', batch_size, DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the images\n",
    "\n",
    "print(images[:10,...])\n",
    "\n",
    "imgs_to_visualize = tfgan.eval.image_reshaper(images[:10,...], num_cols=10)\n",
    "visualizer.pre_train_image(imgs_to_visualize, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dims = 8 * 8  # shape of noise generation\n",
    "\n",
    "conditional_gan_model = tfgan.gan_model(generator_fn=tf_nets.generator,\n",
    "                                        discriminator_fn=tf_nets.discriminator,\n",
    "                                        real_data=images,\n",
    "                                        generator_inputs=(tf.random_normal([batch_size, noise_dims]),one_hot_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pre-training generator images\n",
    "cond_generated_data_to_visualize = tfgan.eval.image_reshaper(conditional_gan_model.generated_data[:10,...], num_cols=10)\n",
    "visualizer.pre_train_image(cond_generated_data_to_visualize, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tfgan.gan_loss(conditional_gan_model, gradient_penalty_weight=1.0)\n",
    "evaluate.gan_loss(loss)  # test loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(0.0009, beta1=0.5)  # instantiate optimizers\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(0.00009, beta1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_train_ops = tfgan.gan_train_ops(conditional_gan_model, loss, generator_optimizer, discriminator_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_eval = 500\n",
    "assert images_to_eval % 10 == 0  # ensure multiples of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_noise = tf.random_normal([images_to_eval, 64])\n",
    "one_hot_labels = tf.one_hot([i for _ in range(images_to_eval // 10) for i in range(10)], depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(conditional_gan_model.generator_scope, reuse=True):\n",
    "    eval_images = conditional_gan_model.generator_fn((random_noise, one_hot_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editing\n",
    "\n",
    "reshaped_eval_imgs = tfgan.eval.image_reshaper(eval_images[:100, ...], num_cols=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pretrained classifier to save on training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_CLASSIFIER_FROZEN_GRAPH = 'mnist/data/classify_mnist_graph_def.pb'  # frozen graph from google\n",
    "xent_score = util.mnist_cross_entropy(eval_images, one_hot_labels, MNIST_CLASSIFIER_FROZEN_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "train_step_fn = tfgan.get_sequential_train_steps()\n",
    "\n",
    "loss_values, xent_score_values = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the FlowGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()  # instantiate saver\n",
    "    init = tf.global_variables_initializer()  # initialize variables\n",
    "    sess.run(init)  # run!\n",
    "\n",
    "    with slim.queues.QueueRunners(sess):        \n",
    "        start_time = time.time()  # start timer\n",
    "        for i in range(1001):  # number of steps - reduced from 5000 for run time\n",
    "            cur_loss, _ = train_step_fn(sess, gan_train_ops, global_step, train_step_kwargs={})            \n",
    "            loss_values.append((i, cur_loss))\n",
    "\n",
    "            if i % 25 == 0:  # \n",
    "                xent_score_values.append((i, sess.run(xent_score)))\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Step {i}.\")\n",
    "                print(f'Current loss: {cur_loss:.2f}')\n",
    "                print(f'Current cross entropy score: {xent_score_values[-1][1]:.2f}')\n",
    "                visualizer.generated_image(i, start_time, sess.run(reshaped_eval_imgs), save=True)\n",
    "                plt.show()\n",
    "\n",
    "        #  program complete\n",
    "        save_path = saver.save(sess, \"assets/saved_models/model.ckpt\")\n",
    "        print(f\"Model saved in file: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt cross entropy score\n",
    "plt.title('Cross Entropy Score Per Step')  # plot cross entropy scores\n",
    "plt.plot(*zip(*xent_score_values))\n",
    "plt.savefig('cross_entropy.png', dpi=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.title('Training Loss Per Step')\n",
    "plt.plot(*zip(*loss_values))\n",
    "plt.savefig('loss.png', dpi=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
